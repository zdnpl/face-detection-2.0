<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Face Detection</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous" />
  </head>
  <body>
    <video id="video" autoplay style="display: none"></video>
    <canvas id="canvas" width="600px" height="400px" style="margin: auto"></canvas>
    <p>zdnpl</p>
    <audio src="audio/face detected.mp3" id="sound"></audio>
  </body>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>

  <script>
    let video = document.getElementById("video");
    let model;
    let canvas = document.getElementById("canvas");
    let ctx = canvas.getContext("2d");

    const setupCamera = () => {
      navigator.mediaDevices
        .getUserMedia({
          video: { width: 600, height: 400 },
          audio: false,
        })
        .then((stream) => {
          video.srcObject = stream;
        });
    };

    const detectFaces = async () => {
      const prediction = await model.estimateFaces(video, false);

      //console.log(prediction);

      ctx.drawImage(video, 0, 0, 600, 400);

      prediction.forEach((pred) => {
        ctx.beginPath();
        ctx.lineWidth = "4";
        ctx.strokeStyle = "lime";
        ctx.rect(pred.topLeft[0], pred.topLeft[1], pred.bottomRight[0] - pred.topLeft[0], pred.bottomRight[1] - pred.topLeft[1]);
        ctx.stroke();

        ctx.fillStyle = "red";
        pred.landmarks.forEach((landmark) => {
          ctx.fillRect(landmark[0], landmark[1], 5, 5);
        });
        //console.log("face detected");
        sound.play();
      });
    };

    setupCamera();
    video.addEventListener("loadeddata", async () => {
      model = await blazeface.load();
      setInterval(detectFaces, 60); //100
    });
  </script>
</html>
